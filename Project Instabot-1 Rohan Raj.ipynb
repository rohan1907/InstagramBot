{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys                            #provide keys in the keyboard like RETURN, F1, ALT\n",
    "from selenium.webdriver.support.ui import Select                           #to select the option html attribute\n",
    "from selenium.webdriver.support.ui import WebDriverWait                    #To use implcit and explicit wait\n",
    "from selenium.webdriver.support import expected_conditions as EC           #use in explicitly wait\n",
    "from selenium.webdriver.common.by import By                                #to select the attribute by Class,link_text\n",
    "from selenium import webdriver                                             #import web Driver\n",
    "import time                                                                #it use in wait\n",
    "from bs4 import BeautifulSoup                                              #work with attribute \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Login to your Instagram Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Looking for [chromedriver 86.0.4240.22 linux64] driver in cache \n",
      "[WDM] - File found in cache by path [/home/deadwalker/.wdm/drivers/chromedriver/86.0.4240.22/linux64/chromedriver]\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "browser.get('https://www.instagram.com/') #starting the webdriver sesion\n",
    "wait = WebDriverWait(browser, 10) \n",
    "def login(): #login function\n",
    "    time.sleep(4)\n",
    "    name = browser.find_element_by_name(\"username\") #locate the username column\n",
    "    name.send_keys(\"username\")\n",
    "    time.sleep(1)\n",
    "    password=browser.find_element_by_name(\"password\") #locate the password column\n",
    "    password.send_keys(\"password\")\n",
    "    password.submit()\n",
    "    time.sleep(4)\n",
    "    btn=browser.find_element_by_class_name(\"bIiDR\") #locate the not now button\n",
    "    btn.click()\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Type for “food” in search bar and print all the names of the Instagram Handles that are displayed in list after typing “food”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_food_overdose_\n",
      "yourfoodlab\n",
      "food_quest824\n",
      "foodnetwork\n",
      "foodys\n",
      "foodwarsofficial\n",
      "food\n",
      "the_food_saucer\n",
      "foodie_incarnate\n",
      "thisisdelhi\n",
      "foodandwine\n",
      "foodrush.recipe\n",
      "foodyeating\n",
      "foodistamysuru\n",
      "foodporn\n",
      "bongeats\n",
      "foodranchi\n",
      "bbcfood\n",
      "ndtv_food\n",
      "foodpandaindia\n",
      "travellerritu\n",
      "foodinsider\n",
      "food_hotel_reviewer\n",
      "wirallyfood\n",
      "food.darzee\n",
      "goodfoodau\n",
      "food52\n",
      "foodlty\n",
      "wowfood5\n",
      "ranchi_food_walks\n",
      "fooddotcom\n",
      "food._.sustenance\n",
      "ziaflavia_foodnboobs\n",
      "drooling__over__food\n",
      "mumbaifoodie\n",
      "delicioushealthyvideos\n",
      "chaturvedineha10_\n",
      "satshyaa\n",
      "fao\n",
      "foodsceneindia\n",
      "foodbible\n",
      "insight_food\n",
      "food_mantraa\n",
      "foodzoo2\n",
      "fooodidilse\n",
      "food_babe2.0\n",
      "italyfoodprn\n"
     ]
    }
   ],
   "source": [
    "def search_food():   \n",
    "    a=browser.find_element_by_xpath('//input[contains(@class,\"XTCLo\")]') #locate the search button\n",
    "    a.send_keys('food') #passing food as search text\n",
    "    time.sleep(3)       #sleep 3 sec.\n",
    "    handles = browser.find_elements_by_xpath('//div[@class = \"fuqBx\"]/a[\"href\"]') #fecting top food list hadles \n",
    "    food_list = []   \n",
    "    for i in handles:\n",
    "        if 'explore' in i.get_attribute('href'):#if explore present in link then it is hastags\n",
    "            continue\n",
    "        else:       \n",
    "            s = i.get_attribute('href').split('/')  #https://www.instagram.com/foodtalkindia\n",
    "            print(s[3]) # after split s= ['https:','','www.instagram.com','foodtalkindia']\n",
    "            food_list.append(s[3])  #appending s[3] in food_list       \n",
    "    a.clear() #clear the search box\n",
    "search_food()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Open profile of “So Delhi”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_user():\n",
    "    usr=\"So Delhi\"\n",
    "    text=browser.find_element_by_class_name(\"XTCLo\") #Click on the search button\n",
    "    text.clear() #clear the search column\n",
    "    text.send_keys(usr) #Enter the text into the column\n",
    "    time.sleep(2)\n",
    "    find=browser.find_element_by_class_name(\"yCE8d\") #click on the given id\n",
    "    find.click()\n",
    "    time.sleep(5)\n",
    "    browser.back()\n",
    "\n",
    "find_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.a)Start following the instagram handle of \"sodelhi\". Print a message if you are already following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not following So Delhi\n",
      "You are now following  So Delhi\n"
     ]
    }
   ],
   "source": [
    "usr=\"So Delhi\"\n",
    "def follow_profile():\n",
    "    text=browser.find_element_by_class_name(\"XTCLo\") #Click on the search button\n",
    "    text.clear() #clear the search column\n",
    "    text.send_keys(usr) #Enter the text into the column\n",
    "    time.sleep(2)\n",
    "    find=browser.find_element_by_class_name(\"yCE8d\") #click on the given id\n",
    "    find.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    btn = browser.find_elements_by_css_selector('button')\n",
    "    \n",
    "    for i in btn:\n",
    "        if i.text !='':\n",
    "            if i.text==\"Message\":\n",
    "                print(\"You are already following So Delhi\")\n",
    "                time.sleep(2)\n",
    "                browser.back()\n",
    "                break\n",
    "            else:\n",
    "                print(\"You are not following \"+usr)\n",
    "                btn=browser.find_element_by_class_name(\"_5f5mN\") #click on the follow button\n",
    "                btn.click()\n",
    "                print(\"You are now following  \"+usr)\n",
    "                time.sleep(2)\n",
    "                browser.back()\n",
    "                break\n",
    "    \n",
    "follow_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.b) After following, unfollow the instagram handle. Print a message if you have already unfollowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are following So Delhi\n",
      "You have now unfollowed So Delhi\n"
     ]
    }
   ],
   "source": [
    "usr=\"So Delhi\"\n",
    "def profile():\n",
    "    text=browser.find_element_by_class_name(\"XTCLo\") #Click on the search button\n",
    "    text.clear() #clear the search column\n",
    "    text.send_keys(usr) #Enter the text into the column\n",
    "    time.sleep(2)\n",
    "    find=browser.find_element_by_class_name(\"yCE8d\") #click on the given id\n",
    "    find.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    btn = browser.find_elements_by_css_selector('button')\n",
    "    \n",
    "    for i in btn:\n",
    "        if i.text !='':\n",
    "            if i.text==\"Message\":\n",
    "                unfollow()\n",
    "                break\n",
    "            else:\n",
    "                print(\"You have already Unfollowed So Delhi\")\n",
    "                time.sleep(2)\n",
    "                browser.back()\n",
    "                break\n",
    "\n",
    "def unfollow():\n",
    "    time.sleep(3)\n",
    "    btn=browser.find_element_by_class_name(\"_5f5mN\") #click on the follow button\n",
    "    btn.click()\n",
    "    time.sleep(3)\n",
    "    btn = browser.find_elements_by_css_selector('button')\n",
    "    for button_search in btn:\n",
    "        if(button_search.text == 'Unfollow'):\n",
    "            print(\"You are following \"+usr)\n",
    "            button_search.click()\n",
    "            print(\"You have now unfollowed \"+usr)\n",
    "            time.sleep(2)\n",
    "            browser.back()\n",
    "            break\n",
    "profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.a) Liking the top 30 posts of the ‘dilsefoodie'. Print message if you have already liked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Liked the 1th Post\n",
      "Already Liked the 2th Post\n",
      "Already Liked the 3th Post\n",
      "Already Liked the 4th Post\n",
      "Already Liked the 5th Post\n"
     ]
    }
   ],
   "source": [
    "#liking the posts\n",
    "search = browser.find_element_by_xpath('//div[contains(@class,\"LWmhU\")]/input')     #input box\n",
    "search.send_keys('dilsefoodie')                                                    #sending keys\n",
    "b = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'z556c')))            #searching sodelhi profile  \n",
    "b.click()    \n",
    "time.sleep(4)\n",
    "post=browser.find_element_by_class_name(\"_9AhH0\")\n",
    "post.click()\n",
    "for i in range(30):\n",
    "    time.sleep(5)\n",
    "    nexb=browser.find_element_by_class_name(\"_65Bje\")\n",
    "    like_btn = browser.find_element_by_xpath('//span[contains(@class,\"fr66n\")]/button')\n",
    "    Check_ctn = browser.find_element_by_xpath('//span[contains(@class,\"fr66n\")]/button/*[name()=\"svg\"]')\n",
    "    if Check_ctn.get_attribute('aria-label') == 'Unlike':#checking status\n",
    "        print(\"Already Liked the {}th Post\".format(i+1))#for like button    \n",
    "    else:\n",
    "        like_btn.click()\n",
    "    time.sleep(4)\n",
    "    nexb.click()\n",
    "close_btn = browser.find_element_by_xpath('//div[contains(@class,\"BI4qX\")]/button')                        # post close button\n",
    "close_btn.click()\n",
    "time.sleep(2)\n",
    "tool=browser.find_element_by_class_name(\"oJZym\")\n",
    "tool.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unliking the top 30 posts of the ‘dilsefoodie’. Print message if you have already unliked it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unliking the posts\n",
    "search = browser.find_element_by_xpath('//div[contains(@class,\"LWmhU\")]/input')     #input box\n",
    "search.send_keys('dilsefoodie')                                                    #sending keys\n",
    "b = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'z556c')))            #searching sodelhi profile  \n",
    "b.click()    \n",
    "time.sleep(4)\n",
    "post=browser.find_element_by_class_name(\"_9AhH0\")\n",
    "post.click()\n",
    "for i in range(30):\n",
    "    time.sleep(5)\n",
    "    nexb=browser.find_element_by_class_name(\"_65Bje\")\n",
    "    like_btn = browser.find_element_by_xpath('//span[contains(@class,\"fr66n\")]/button')\n",
    "    Check_ctn = browser.find_element_by_xpath('//span[contains(@class,\"fr66n\")]/button/*[name()=\"svg\"]')\n",
    "    if Check_ctn.get_attribute('aria-label') == 'Like':#checking status\n",
    "        print(\"Already Unliked the {}th Post\".format(i+1))#for like button    \n",
    "    else:\n",
    "        like_btn.click()\n",
    "    time.sleep(4)\n",
    "    nexb.click()\n",
    "close_btn = browser.find_element_by_xpath('//div[contains(@class,\"BI4qX\")]/button')                        # post close button\n",
    "close_btn.click()\n",
    "time.sleep(2)\n",
    "tool=browser.find_element_by_class_name(\"oJZym\")\n",
    "tool.click()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the usernames of the first 500 followers of ‘foodtalkindia’ and \"sodelhi\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "The followers of foodtalkindia are:\n",
      "----------------------------------------------------------------------------\n",
      "arnav_mehraaa\n",
      "thespicedlime\n",
      "food_fetish_diaries\n",
      "myfoodthela\n",
      "ipoojaabairwa\n",
      "ojusvni_kapur\n",
      "sana1__0\n",
      "_iam_umar_d\n",
      "aasthasahdev20\n",
      "namdevbailurkar\n",
      "shbhatnagar\n",
      "i_ts_v_a_n_s_h\n",
      "almosteverythingggg\n",
      "siyaksharma\n",
      "mr_anno_afc\n",
      "nahida_q1990\n",
      "eats.ok\n",
      "13jat_26\n",
      "blu_view\n",
      "s.m800_\n",
      "damnitdam\n",
      "iyaarjokar\n",
      "_e.l.y.s.i.a.n_07\n",
      "fernresidency\n",
      "sidharthsaini63\n",
      "i_m_praveenrawat\n",
      "kapila_miglani\n",
      "bareeranajam\n",
      "chef.sau_ras\n",
      "x_sameer_92\n",
      "mr.prashanth007\n",
      "aniketgurav4141\n",
      "mr.rateria\n",
      "bhavesh.pathade\n",
      "smoker_sangam\n",
      "rcmpinternational\n",
      "the_food_philosophy25\n",
      "foodrambler19\n",
      "ekta_kunal\n",
      "awara_azaad_aurat\n",
      "officialfoodietiger\n",
      "ohchewyindia\n",
      "richa9942\n",
      "santhu.krishnna\n",
      "foodily_ever_after\n",
      "noicelydonee\n",
      "sauravsoos\n",
      "acookingtour7\n",
      "abhishekjain841989\n",
      "___7596___\n",
      "----------------------------------------------------------------------------\n",
      "The followers of sodelhi are:\n",
      "----------------------------------------------------------------------------\n",
      "santtosha\n",
      "dhiraj_8010\n",
      "sshivangi.sharma\n",
      "ga_urav2798brahman\n",
      "simpleliving941\n",
      "personawhoami_\n",
      "thespicedlime\n",
      "oooohnavii\n",
      "bhavyabsqr\n",
      "0ffical_vinay\n",
      "foodies_cooknook\n",
      "parth.bhatt.146\n",
      "mldhaka\n",
      "_aditiii17\n",
      "arollmachine\n",
      "jassika_kumar\n",
      "real_in_reel_\n",
      "quotes_book_world.in\n",
      "sachdevpriya\n",
      "___itztausif_\n",
      "bumptobunny\n",
      "_iam_umar_d\n",
      "_dien420_\n",
      "fitmomsumeet\n",
      "sugandh_memes\n",
      "_monika.mv\n",
      "wm.shaikh\n",
      "starcopiers\n",
      "aashri_creations\n",
      "digitec_yatra_tours\n",
      "shaanmalik9\n",
      "aditi__8217\n",
      "mahima_malik\n",
      "cuttieaanvi\n",
      "_yatikaarya_\n",
      "idio_syncratic_love\n",
      "yashproperty_0177\n",
      "narang_3994\n",
      "toyeshbhardwaj\n",
      "mr_mukulrana\n",
      "jmdpoolsindia\n",
      "nushhwrites_\n",
      "chetan_0089\n",
      "lomodoodles\n",
      "neelvin_stration\n",
      "manju.s16\n",
      "gurawaprincy\n",
      "anurag07___\n",
      "_the_lost_monk\n",
      "sushil.blink\n"
     ]
    }
   ],
   "source": [
    "u_ser=[\"foodtalkindia\",\"sodelhi\"]\n",
    "\n",
    "for i in u_ser: #iterating over the user profiles\n",
    "    search = browser.find_element_by_xpath('//div[contains(@class,\"LWmhU\")]/input') #input box\n",
    "    search.send_keys(i)\n",
    "    first_search = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'z556c'))) #first profile\n",
    "    first_search.click()\n",
    "    time.sleep(2)\n",
    "    follower = browser.find_element_by_partial_link_text(\"follower\")\n",
    "    follower.click()\n",
    "    time.sleep(4)\n",
    "    followersList = browser.find_element_by_css_selector('div[role=\\'dialog\\'] ul')\n",
    "    numberOfFollowersInList = len(followersList.find_elements_by_css_selector('li'))\n",
    "\n",
    "\n",
    "    followersList.click()\n",
    "    actionChain = webdriver.ActionChains(browser)\n",
    "    while (numberOfFollowersInList < 500):\n",
    "        actionChain.key_down(Keys.SPACE).key_up(Keys.SPACE).perform()\n",
    "        numberOfFollowersInList = len(followersList.find_elements_by_css_selector('li'))\n",
    "\n",
    "    followers = []\n",
    "    for user in followersList.find_elements_by_css_selector('li'):\n",
    "        userLink = user.find_element_by_css_selector('a').get_attribute('href')\n",
    "        followers.append(userLink)\n",
    "        if (len(followers) == 500):\n",
    "            break\n",
    "    print(\"----------------------------------------------------------------------------\")        \n",
    "    print(\"The top 500 followers of {} are:\".format(i))\n",
    "    print(\"----------------------------------------------------------------------------\")        \n",
    "\n",
    "    for i in followers:\n",
    "        print(i.split(\"/\")[3])\n",
    "\n",
    "    browser.back()\n",
    "    browser.back() #moving back to the main page\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gurawaprincy\n",
      "anurag07___\n",
      "_the_lost_monk\n",
      "sushil.blink\n",
      "iam_sanjanaa\n",
      "basicallyjobless_\n",
      "laiba.in\n",
      "sonusaifi6122\n",
      "santtosha\n",
      "shariq_siddique78\n",
      "shaliniagrawal_02\n",
      "gudduyadav425\n",
      "digging_dreams\n",
      "artenstein_\n",
      "kavnkia_sachdeva\n",
      "priyankas.aroras\n",
      "what_where_she_ate\n",
      "suchismita403\n",
      "the.painters.blog\n",
      "the.opulent.nomad\n",
      "dev.devdhar\n",
      "itsishaniarora\n",
      "vaibhav__chandhok\n",
      "designby.rb\n",
      "aakshisings\n",
      "daudkhann\n",
      "sumandagar3946\n",
      "ss_thebongfoodies\n",
      "dantani.raj.397\n",
      "gujral_tanyaa\n",
      "kascera_by_ritu\n",
      "mr_danish_writes_\n",
      "umf080\n",
      "meristorieshai\n",
      "kabir_rao0703\n",
      "_aditya_aggarwal\n",
      "___s.w.a.s.t.i.k.a___99\n",
      "bhavisha200\n",
      "ashm33t\n",
      "deepakpandey129\n",
      "mouniminne\n",
      "nikitaagarwal63\n",
      "_itz_akky_07_\n",
      "mug_of_pens\n",
      "ghosh_prerna\n",
      "tusharsierra\n",
      "manya.uppal16\n",
      "alishash687\n",
      "real_graphy_\n",
      "saurabhdex\n",
      "captions_gram\n",
      "cromulent_asf\n",
      "tan.veeer\n",
      "mohdvaisar\n",
      "quarantine_recipe\n",
      "chaitanyamunjal\n",
      "renikuntahasya\n",
      "tanyakhanna96\n",
      "drathore.____\n",
      "officialarshkaur\n",
      "ishika_khaneja_31\n",
      "ciel_sombre_\n",
      "sumitkumar826\n",
      "sswadesh\n",
      "garima.gupta8\n",
      "iraagrawal\n",
      "prashantrajput179\n",
      "yashie_._._\n",
      "bacchic_guy\n",
      "reyes17jr\n",
      "unique_ramgharia_002\n",
      "ssneha_art\n",
      "insta_meya\n",
      "nirmaanmalhotra\n",
      "it_is_ankiit\n",
      "callmemaybekanks\n",
      "shivam_kori_\n",
      "kiitabuddin\n",
      "its_all_about_timing\n",
      "tanmay.malhotra.in\n",
      "purnalaxmishrestha\n",
      "iamanishyadav\n",
      "indergyani\n",
      "lovely_vicky1432\n",
      "muditaa.a\n",
      "illusion_photography09\n",
      "chirag_seghal09\n",
      "mr.poet2003\n",
      "rajan015\n",
      "ankita.kabir\n",
      "sanjanapambi\n",
      "kusu0_0\n",
      "behlniharika\n",
      "roshni.gariya\n",
      "dev.z\n",
      "hydrhydr9333\n",
      "got_no_otherjob_\n",
      "kdpv.tt\n",
      "bedii_jas\n",
      "kuldeep_cic\n",
      "sanjeevanii_shiraskarr\n",
      "mukul2530\n",
      "anjaan___123\n",
      "the_cosmic_stark\n",
      "manaswimadicheffy\n",
      "rudransh_chauhan\n",
      "janvi_aroraa\n",
      "jyotihotel14\n",
      "quotes_.off\n",
      "saahilpanjwani\n",
      "_natasha_sh1\n",
      "fiver_food\n",
      "bhanudhakyouw\n",
      "rajat__1999\n",
      "puriuppal\n",
      "iamsumitdedha\n",
      "arshad_dxb\n",
      "areaderahead\n",
      "radhika_arora1997\n",
      "harshpreetkaurb\n",
      "khurana__24\n",
      "tanvi.aggarwal13\n",
      "random.account.pvt\n",
      "donttlookkforrmee\n",
      "_gtsss\n",
      "grey_obscura\n",
      "sandeep_parte_\n",
      "foodislife1419\n",
      "the_sudhakar\n",
      "a.g.pvt\n",
      "sumriddhimittal\n",
      "saadifoodiekismat\n",
      "rajvansh.rockx7\n",
      "my_wordszz\n",
      "arora__reet\n",
      "queen.mishii\n",
      "fuckkkmylife_\n",
      "elysianascuas\n",
      "aadi__saini\n",
      "yashpratap_2303\n",
      "zoi.naa\n",
      "helpinghands_slc\n",
      "lunch.box187\n",
      "faithsamuel2\n",
      "manjushagogna\n",
      "shu.bhi1306\n",
      "shadkhan498\n",
      "khaniqra753\n",
      "redddyyy_k\n",
      "dhruv_pal21\n",
      "momoskitchenn\n",
      "thestroller_\n",
      "monika.vipin\n",
      "mikhan981\n",
      "nayangupta_photography\n",
      "rush.n.crush\n",
      "_navya_lal_\n",
      "radha2705\n",
      "monserrat_67231\n",
      "hotel_shakun_palace\n",
      "epickanpuriya\n",
      "buyavocados\n",
      "___befikre___\n",
      "spill_the_sassss\n",
      "parthsingh000\n",
      "shubham_999_\n",
      "rahulnarang15\n",
      "vrndrsngh19\n",
      "pushpa.dangwal\n",
      "priyanka_sehgal0408\n",
      "sehbsss\n",
      "ancia.joseph\n",
      "countertop.by.anubha\n",
      "bhavnasharma251\n",
      "ra.hulsingh448\n",
      "kritzzz.03\n",
      "_rahuldalal_\n",
      "anubhadube\n",
      "raghavashu1\n",
      "momsilam\n",
      "jesta_de_acosta\n",
      "i.m.a.doodler\n",
      "nisha_jain069\n",
      "srishti_jain23\n",
      "brandedfakeer\n",
      "vaibhav_dalal\n",
      "harshit_rastogi1\n",
      "aastha000\n",
      "unboxwishlistbyroshni\n",
      "rachnapvttt\n",
      "shagun.pandeyy\n",
      "divya_midha\n",
      "jerrriiiinnnstagram\n",
      "c_h_i_r_a_g_9\n",
      "miles.n.mealz\n",
      "khaane_se_mohabbat\n",
      "_priyankajha_\n",
      "wanderoushka\n",
      "_urvashisinghal_\n",
      "vershaagupta\n",
      "blueskymelo\n",
      "uditsethi1\n",
      "gulpinggang\n",
      "gauri4681\n",
      "kumarrajneesh7532\n",
      "adisphotographysg\n",
      "fa_ix_u\n",
      "angadsingh3011\n",
      "quuuiinnzzaaaa\n",
      "deeksha8164\n",
      "dipanshukhanna\n",
      "khansamir4200\n",
      "manviichauhan\n",
      "kaavya_thukrral\n",
      "_sheena.bhatia_\n",
      "meghamehra___\n",
      "namra_.ansari\n",
      "_hemangiii\n",
      "vijayvijay4827\n",
      "pratiksha_sharma02\n",
      "ankitjoshiiii\n",
      "dua.jatin.1\n",
      "fadhilakaramath\n",
      "50so_flavours\n",
      "nehaanand25\n",
      "iamgarima_\n",
      "_akash.81_\n",
      "nupur.m25\n",
      "_frame_memories_\n",
      "tom_n_jerry_cookbook\n",
      "mkunal05\n",
      "prernaayo\n",
      "puneetchoudhary23\n",
      "jayant.alpha\n",
      "soumits_kitchen\n",
      "geetadhingra45\n",
      "mehtasuman714\n",
      "beautiful_world40\n",
      "kashina_chadha\n",
      "clixle\n",
      "shreyaa03_\n",
      "_sg__041995\n",
      "meraki_dreamss\n",
      "__iamabhinavarora\n",
      "nahshon_williams\n",
      "reet_8891\n",
      "showbhet\n",
      "akshatsharma10_\n",
      "namratarai177\n",
      "eladhwan\n",
      "kabhiekabhiaditi\n",
      "inmypocket2020\n",
      "hey.vineet\n",
      "riteshprajapat7\n",
      "shufflestudio.gurgaon\n",
      "sujitmandal923\n",
      "dr.reematushamer\n",
      "escapist.x_x\n",
      "ridima_kamal\n",
      "amanbhai_00\n",
      "tanishqa_20\n",
      "lakshyaa.pvt\n",
      "livingaminimallife\n",
      "hungry.men\n",
      "its_jaan_777\n",
      "aadi_.singhania\n",
      "vikas231007\n",
      "vmsevents\n",
      "notashake\n",
      "asmatinterior_indore\n",
      "tanya_solanki_98\n",
      "rahulgaba1\n",
      "ryashasvi.a\n",
      "geetajaiswal448\n",
      "rohankshetry1\n",
      "shifa2304\n",
      "pratishtha1802\n",
      "lust_.for_.life_\n",
      "avinash0222\n",
      "abhikabhi__\n",
      "komalchouhan681\n",
      "piiyushtiwari\n",
      "shivank_parashar\n",
      "shobhit240901\n",
      "withlovefood_\n",
      "atmosfares\n",
      "vandanakaushal11\n",
      "ms_jahanvi\n",
      "puneetsawhneyy\n",
      "wearekalakrit\n",
      "canopycreature\n",
      "irfansehti\n",
      "nawab5907\n",
      "walkwithsarthak\n",
      "lifeisnowexpeditions\n",
      "alisha3584\n",
      "khichick__\n",
      "_pixcellence_\n",
      "devendrapanchal1988\n",
      "__its__suali\n",
      "nishu_2610\n",
      "the_phoenixeye\n",
      "iamparthavitaluja\n",
      "shubh4real\n",
      "littlewindowbigdreams\n",
      "sophiagomes92\n",
      "b.se.baklol\n",
      "juneadchoudahr\n",
      "aakashprateik\n",
      "yin9989\n",
      "quotes_book_world.in\n",
      "_priyanka_dikonda_\n",
      "kartik.nirman\n",
      "pratiksh960\n",
      "amandaudzai\n",
      "shreyaverma.30\n",
      "akshataparul04\n",
      "chasseur_des_bois\n",
      "aaishabella\n",
      "dr.jyoti_sharmaa\n",
      "hayer_parm_191\n",
      "naam_hai_som\n",
      "abhinav_abr\n",
      "nvgxruibxdrin\n",
      "rahulskitchen_og\n",
      "anjali.official\n",
      "riyaayy\n",
      "prafful_99\n",
      "ankita.ghadi.5494\n",
      "prabhumehta_\n",
      "banished.ecstasy\n",
      "the.tanushmita.narang\n",
      "sanam_sbw\n",
      "lakshay_1080\n",
      "aaman299\n",
      "tanyadhingra_10_\n",
      "_rishugoyal_\n",
      "singhpanesargurpreet\n",
      "bhumiyachawla13\n",
      "gaba_parveen_\n",
      "sainidevika\n",
      "theperspicaciouscompanion\n",
      "ritikgarg012\n",
      "minzpreeti\n",
      "aggrawal7134\n",
      "talib.moin.7\n",
      "rose_of_sharon.11\n",
      "rishabhbatra_photography\n",
      "malakarshreya\n",
      "gautamrachna05\n",
      "yashika.idk\n",
      "abdulsamadmolli\n",
      "parthh_malhotra\n",
      "asmita_khanna\n",
      "shootguru\n",
      "tannyaa11\n",
      "_.agrim\n",
      "sublime_shot\n",
      "maneesh_4\n",
      "sahilgaba79\n",
      "dixit.kumbhani\n",
      "quotesandproverbs28\n",
      "subaranas\n",
      "vipulbhatt75\n",
      "bubble1892\n",
      "aartib28\n",
      "madhuriiima\n",
      "prernasachdevaaa\n",
      "ditesh0100\n",
      "thesavourygrub\n",
      "afreenalii\n",
      "harshitaasharmaa_\n",
      "dubeyvivekkumardubey\n",
      "telegraphytales\n",
      "fazal__rehan\n",
      "mindrunway\n",
      "coder_who_cooks\n",
      "shrutisaxena20\n",
      "randomaart\n",
      "sakshibajaj99\n",
      "scribbled_quotes.u\n",
      "deliciousdestinations\n",
      "harshsriv.08\n",
      "hitali_panwar\n",
      "amninder_vohra_\n",
      "random_uploads16\n",
      "lockdownmasterchef2020\n",
      "drapmeonline\n",
      "metanoiainframes\n",
      "bhardwwaj_nishant\n",
      "123_kash\n",
      "tulasidaspai\n",
      "__sagarwal__\n",
      "bcmeme_2126\n",
      "abhi.banga_\n",
      "deepak0092\n",
      "shivani__20.01\n",
      "kanchanhatwal17213\n",
      "sha__swat007\n",
      "abhishek.gupta90\n",
      "srishh__t_02\n",
      "siddhantsagar\n",
      "chill_n_chull\n",
      "dev_en_dra\n",
      "imrahulmaddheshiya\n",
      "deepak_shar3a\n",
      "in.harshalgupta\n",
      "enteradesigne\n",
      "hikeingwithme\n",
      "simar_shooter\n",
      "omyronshwal\n",
      "shanayaoberio2\n",
      "nehadahmad7\n",
      "vexplorers.in\n",
      "sava.lakh\n",
      "ambalal.jain.obain\n",
      "riya.sharma160\n",
      "ruhi_sinhaa\n",
      "jain_yakshi\n",
      "gill_suraj1998\n",
      "bar_sha_roy\n",
      "gabber661\n",
      "agirlondelhimetro\n",
      "rahul.m24\n",
      "nainamk\n",
      "user_pages\n",
      "khaana_rozana\n",
      "soniya_krishna_\n",
      "sunny_yadav_sunny\n",
      "foodie_tune_indore\n",
      "0_1_palak\n",
      "_attrihoney_\n",
      "me.neha2k2\n",
      "kaustavdey_23\n",
      "devashi_aggarwal11\n",
      "gaurav_7032\n",
      "nervousplanetbubble\n",
      "prernaverma48\n",
      "devansh.sehgal\n",
      "mohitpal7582\n",
      "pisthieee\n",
      "sajan.nigam.39\n",
      "kunar8505\n",
      "s4sumitd4dahiya\n",
      "ashraf78630\n",
      "klutzykiara\n",
      "debolinadevnath\n",
      "nehayadav.nk123\n",
      "raj_shubham_\n",
      "sparsh_153\n",
      "sanjayrajput9718\n",
      "_alvi_1998\n",
      "iamadhil\n",
      "sai_likhitha_gs\n",
      "shabib_shaikh786\n",
      "_shivamgrover\n",
      "jyoti.mittal.5437\n",
      "hmaheshwari6\n",
      "shripal6158\n",
      "aymanzuha\n",
      "theeyefocus\n",
      "muhammadyusuf2133\n",
      "pavan_renge_patil\n",
      "iamaasthakaushik\n",
      "shree_k15\n",
      "foodiejunction98\n",
      "alwaysbruffon\n",
      "davinkaur30\n",
      "singhal9751\n",
      "feed_the_needy980\n",
      "ishita902\n",
      "gurpreet_._.1\n",
      "jyotiorator\n",
      "quotes__.day\n",
      "prateethi\n",
      "shubhiiix_pvttt\n",
      "pagal_kalakaarr\n",
      "sharma45054505\n",
      "piczones\n",
      "sharma_bharti99\n",
      "saurbh5554\n",
      "kanishq_basoya_delhi0005\n",
      "sabmohmayahai_23\n",
      "kajal_777\n",
      "shrestha_nanda\n",
      "the.foodiee.vogue\n",
      "rahulmeena1_2_3\n",
      "talk_less_word\n",
      "asous13asous\n",
      "surbhiaroraaaa\n",
      "kishan_thakre\n",
      "voyagedairy\n",
      "anjalisainii\n",
      "dev_adhikary19\n",
      "vandana.s66\n",
      "saadzaidii\n",
      "varshney_vrinda\n",
      "_rai_archana\n",
      "dhananjaydubey_132\n",
      "trisha.verma12\n"
     ]
    }
   ],
   "source": [
    "search = browser.find_element_by_xpath('//div[contains(@class,\"LWmhU\")]/input') #input box\n",
    "search.send_keys('foodtalkindia')\n",
    "first_search = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'z556c'))) #first profile\n",
    "first_search.click()\n",
    "time.sleep(2)\n",
    "followers_button = wait.until(EC.presence_of_element_located((By.XPATH,'//a[contains(@class,\"-nal3\")]')))#follower button\n",
    "followers_button.click()\n",
    "flag = False\n",
    "while True:\n",
    "    p = browser.find_element_by_class_name('isgrP')         #follower page\n",
    "    p.click()\n",
    "    browser.find_element_by_tag_name('body').send_keys(Keys.END)                              #moving to end of page\n",
    "    if flag == False:\n",
    "        for i in range(500):\n",
    "            browser.find_element_by_tag_name('body').send_keys(Keys.PAGE_UP)                  #make 6 time page up to remove first suggestion\n",
    "            time.sleep(1)\n",
    "        flag = True\n",
    "    time.sleep(1)\n",
    "    p = browser.find_element_by_class_name('isgrP')                                          #follwer page\n",
    "    p.click()\n",
    "    follower_list = browser.find_elements_by_xpath('//div[@class = \"isgrP\"]/ul/div/li')      #folllower list\n",
    "    if len(follower_list) >= 500:\n",
    "        break\n",
    "li = []\n",
    "j=0\n",
    "names = []\n",
    "for i in follower_list:\n",
    "    data = BeautifulSoup(i.get_attribute('innerHTML'),'html')                            #alreday explained \n",
    "    li.append(data.a['href'].split('/')[1])\n",
    "    names.append(data.a['href'].split('/')[1])\n",
    "    j+=1\n",
    "    if j==500:\n",
    "        break\n",
    "for i in names:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the story of ‘coding.ninjas’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not checked the story yet\n",
      "Already seen the Story.\n"
     ]
    }
   ],
   "source": [
    "search = browser.find_element_by_xpath('//div[contains(@class,\"LWmhU\")]/input')      #input box  \n",
    "search.send_keys('coding.ninjas')\n",
    "first_search = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'z556c')))  #fisrt profile\n",
    "first_search.click()\n",
    "print('Not checked the story yet')\n",
    "time.sleep(2)\n",
    "try:\n",
    "    a = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'h5uC0')))\n",
    "    if count==1:\n",
    "        print(\"Already seen the Story.\")\n",
    "        time.sleep(2)\n",
    "        browser.back()\n",
    "    else:\n",
    "        a = wait.until(EC.presence_of_element_located((By.CLASS_NAME,'_2dbep')))              #for story check button\n",
    "        a.click()\n",
    "        print(\"Seen the story\")\n",
    "        count+=1\n",
    "        time.sleep(30) #minimum sleep time to see the maximum number of stories\n",
    "        browser.back()\n",
    "        browser.back()\n",
    "    \n",
    "except TimeoutException: #exception timeout\n",
    "    print(\"User don't have a Story.\")\n",
    "    time.sleep(2)\n",
    "    browser.back()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
